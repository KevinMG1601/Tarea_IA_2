{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f6d592c",
   "metadata": {},
   "source": [
    "# Data prep: Edge Impulse \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6f5b52",
   "metadata": {},
   "source": [
    "## 1. Cargar datos y unificar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc0ee17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases detectadas: {'quieto', 'correr', 'girando', 'saltar', 'caminando'}\n",
      "Total muestras: 25\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BASE_DIR = 'C:/Users/kevin/Github/Tarea_IA_2/data' \n",
    "\n",
    "def load_json_data(base_dir):\n",
    "    X, y = [], []\n",
    "    for label in os.listdir(base_dir):\n",
    "        class_path = os.path.join(base_dir, label)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        for fname in os.listdir(class_path):\n",
    "            if fname.endswith('.json'):\n",
    "                with open(os.path.join(class_path, fname), 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                values = data.get('payload', {}).get('values', [])\n",
    "                if not values:\n",
    "                    continue\n",
    "\n",
    "                arr = np.array(values)\n",
    "                if arr.shape[1] != 3:\n",
    "                    continue \n",
    "\n",
    "                X.append(arr)\n",
    "                y.append(label)\n",
    "    return X, y\n",
    "\n",
    "X_raw, y_raw = load_json_data(BASE_DIR)\n",
    "\n",
    "print(f\"Clases detectadas: {set(y_raw)}\")\n",
    "print(f\"Total muestras: {len(X_raw)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d68a85",
   "metadata": {},
   "source": [
    "## 2. Ventaneo\n",
    "Creamos ventanas de longitud `WINDOW_SIZE` (en muestras) con paso `STEP`. Cada ventana produce un tensor `[WINDOW_SIZE, 3]` y una etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac15b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset final: (396, 128, 3) (396,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "WINDOW_SIZE = 128\n",
    "STEP = 32\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def make_windows_json(X_raw, y_raw, window_size=WINDOW_SIZE, step=STEP):\n",
    "    X_out, y_out = [], []\n",
    "    for arr, label in zip(X_raw, y_raw):\n",
    "        arr_scaled = scaler.fit_transform(arr)\n",
    "        for start in range(0, len(arr_scaled)-window_size+1, step):\n",
    "            X_out.append(arr_scaled[start:start+window_size])\n",
    "            y_out.append(label)\n",
    "    return np.array(X_out), np.array(y_out)\n",
    "\n",
    "X, y = make_windows_json(X_raw, y_raw)\n",
    "print('Dataset final:', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762160ac",
   "metadata": {},
   "source": [
    "## 3. Guardar dataset procesado\n",
    "Guardamos los arrays en `.npz` para cargarlos rápido desde el notebook de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8038a336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases detectadas: [np.str_('caminando'), np.str_('correr'), np.str_('girando'), np.str_('quieto'), np.str_('saltar')]\n",
      "Mapa clase → índice: {np.str_('caminando'): 0, np.str_('correr'): 1, np.str_('girando'): 2, np.str_('quieto'): 3, np.str_('saltar'): 4}\n",
      "Dataset guardado en: C:\\Users\\kevin\\Github\\Tarea_IA_2\\data\\data_processed.npz\n"
     ]
    }
   ],
   "source": [
    "classes = sorted(np.unique(y))\n",
    "cls2idx = {c: i for i, c in enumerate(classes)}\n",
    "y_idx = np.array([cls2idx[c] for c in y])\n",
    "\n",
    "print('Clases detectadas:', classes)\n",
    "print('Mapa clase → índice:', cls2idx)\n",
    "\n",
    "OUT_PATH = r\"C:\\Users\\kevin\\Github\\Tarea_IA_2\\data\\data_processed.npz\"\n",
    "\n",
    "os.makedirs(os.path.dirname(OUT_PATH), exist_ok=True)\n",
    "\n",
    "np.savez_compressed(OUT_PATH, X=X, y=y_idx, classes=np.array(classes))\n",
    "\n",
    "print('Dataset guardado en:', OUT_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Logan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
